{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZay1ryJyqEq"
      },
      "source": [
        "\n",
        "# TxMM Assignment 3: Information Extraction\n",
        "## Learning goals of this assignment:\n",
        "1. Become familiar with the intricacies and challenges of time expression labelling\n",
        "2. Practice with manual annotation using BIO tags\n",
        "3. Learn how to compute inter-annotator agreement scores with Cohen’s kappa, and understand how to interpret these kappa scores\n",
        "4. Define a set of patterns for extracting time patterns from text\n",
        "5. Calculate precision for the output of your code on an unseen text\n",
        "6. Gain insight into the importance of pattern generalizability\n",
        "7. Reflect on the gap between labeling time expressions and the actual IE task of extracting and matching events from texts.\n",
        "\n",
        "## Group Assignment\n",
        "\n",
        "This assignment is a group assignment. For this assignment, ensure you are enrolled in an \"Assignment 3 - Information Extraction\" group on Brightspace with a group of three people.\n",
        "\n",
        "\n",
        "## Practical information\n",
        "\n",
        "Note that the assignment will be graded with a Pass/Fail system.\n",
        "\n",
        "Whenever you have any questions, feel free to ask us in the open lunch hours on Mondays! You can also contact the TAs, Mats Robben, Nityaa Kalra and Raul Mihalca through discord or by sending a mail to nityaa.kalra@ru.nl, raul.mihalca@ru.nl and/or mats.robben@ru.nl.\n",
        "\n",
        "We would appreciate it if you do not contact us via WhatsApp for non-urgent matters, so we can keep our TA work and private life (somewhat) separate.\n",
        "\n",
        "We only support the use of [Google Colab](https://https://colab.research.google.com/) as all assignments have been implemented and tested using this. In case of (strange) bugs on other platforms, please consider switching to Colab to make sure that we can provide you with all the help you may need.\n",
        "\n",
        "## Handing in the assignment:\n",
        "Please hand in the following files:\n",
        "- This notebook containing your answers in a .ipynb format.\n",
        "- One .csv file containing all three of your BIO-tag annotations.\n",
        "\n",
        "Please run the notebook before you hand in the assignment.\n",
        "\n",
        "Only one of the group members has to hand in the assignment files on Brightspace."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Assignment\n"
      ],
      "metadata": {
        "id": "aQGEceLJyhAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment consists of two parts: the first part focuses on textual annotation of time expressions and the second part focuses on automatizing time expression extraction with regular expressions and normalizing them to a unified format.\n",
        "\n",
        "The goal of this assignment is to let you practice in annotation labeling and reflect on the challenges when doing manual annotation of time expressions in text.\n",
        "\n",
        "Recognizing time expressions is a crucial part of many NLP and IE applications. In this assignment we focus on date expressions in biography texts from Wikipedia."
      ],
      "metadata": {
        "id": "JiECyZEdyj47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Manual Annotation & Inter-Annotator agreement"
      ],
      "metadata": {
        "id": "aHhy9vvxi2oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading files to Colab\n",
        "\n",
        "Similar to a previous assignment you need to upload some files that are needed for the assignment in the working directory. For this assignment you need to upload the files *Yoshua_Bengio_bio_trainset.txt*,  *Yann_LeCunn_bio_devset.txt*,\n",
        "*Fei-Fei_Li_bio_testset.txt* and *utils.py*.\n",
        "\n",
        "Instead of using the upload functionality, you can also download the file directly in the notebook. Therefore you need to upload the files to https://transfer.sh/ then run the following command in a code cell using the URLs you created:\n",
        "\n",
        "```\n",
        "!wget <transfer.sh url>/Yoshua_Bengio_bio_trainset.txt\n",
        "!wget <transfer.sh url>/Yann_LeCunn_bio_devset.txt\n",
        "!wget <transfer.sh url>/Fei-Fei_Li_bio_testset.txt\n",
        "!wget <transfer.sh url>/utils.py\n",
        "```\n",
        "\n",
        "Pay attention: The links expire after two weeks and you have to create new ones."
      ],
      "metadata": {
        "id": "tDx_fGCe7Nie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that it is not at all important that you achieve and report a high Cohen's kappa for this task. In a real text mining application, researchers often go through multiple cycles of annotation rounds to come up with consistent and clear annotation guidelines. Here you are starting with an initial round of annotations.\n"
      ],
      "metadata": {
        "id": "gS8uTLoqyNcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Perform Manual Annotation\n",
        "Each of you individually annotates the date expressions in the biography text of Yoshua Bengio taken from Wikipedia without discussing the task together. This results in 3 versions (A,B,C) of the text with annotations. *Note: if you work in a group with less than three people it is alright to ask another group for one of their annotations.*\n",
        "\n",
        "A **date expression** is a sequence within the text (can contain letters, numbers, and/or punctuation) that expresses a point in time or a period of time.\n",
        "\n",
        "As annotation labels we use the B (begin), I (inside) and O (outside) labels to indicate if a token is part of a time expression or not.\n",
        "\n",
        "We provide a text with one token per line as a starting point, you can find `Yoshua_Bengio_bio_TPL.csv` in the provided zip file. We advise you to use Excel or another editor that allows you to save the resulting annotations as a CSV file."
      ],
      "metadata": {
        "id": "jEuXpT8NyzhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*After you individually created your annotated versions, combine them into one annotation file. Hand in the file together with this notebook on Brightspace.*"
      ],
      "metadata": {
        "id": "0IRg5glU7z5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Compute Inter-Annotator Agreement\n",
        "Upload the csv file and compute Cohen’s kappa between each pair of annotations (AB,BC,AC) and report the 3 scores. Use sklearn.metrics.cohen_kappa_score for this computation."
      ],
      "metadata": {
        "id": "sF_EuHexzmKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "### BEGIN SOLUTION\n",
        "# import the libraries you need\n",
        "### END SOLUTION\n",
        "\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "# your code goes here\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "id": "rZy1w274zsK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Report on the three scores here*"
      ],
      "metadata": {
        "id": "myepLAaA0RbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Reflect on the Cohen's Kappa score:\n",
        "#### 3.1) How do you interpret the kappa scores? Are all 3 scores similar?  What does a high score indicate?\n",
        "#### 3.2) If you place the three columns of BIO tags next to each other, what are the cases where you disagreed? Can you explain why?\n",
        "#### 3.3) Was the Kappa score metric suitable to evaluate the inter-annotator agreement on this task of time expression labeling, also taking into account the number of annotators?\n"
      ],
      "metadata": {
        "id": "a_Wi_Ndp8RjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your answer here*"
      ],
      "metadata": {
        "id": "H9sQRKxd8tTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Part 2 - Regular Expressions and Normalization *(Extracting timelines and matching events from biographies)*"
      ],
      "metadata": {
        "id": "DsKaC33yi_OA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Loading & inspecting the Yann_LeCunn_bio_devset.txt\n",
        "\n",
        "In this second part you implement a IE program that automatically extracts time expresssions from texts. We focus here on events described in two texts (the biographies of Yann Le Cunn and Fei-Fei Li) and you will find the matching events (i.e. overlapping dates) of the two timelines.\n",
        "\n",
        "Here, your goal is to identify and extract date expressions from sentences.\n",
        "\n",
        "First, you want to get an impression of the date expressions in the biography of Yann Le Cunn.\n",
        "Run the next cell to see Yann_LeCunn_bio_devset.txt. *Don't look at Fei-Fei_Li_bio_testset.txt yet, this is an extraction of the biography of Fei-Fei Li!*"
      ],
      "metadata": {
        "id": "5s55NlOwGwnE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzcCXt38BAJf"
      },
      "source": [
        "import os\n",
        "# Make sure Yann_LeCunn_bio_devset.txt and Fei-Fei_Li_bio_testset.txt are in the working directory.\n",
        "\n",
        "def read_file(file_name):\n",
        "  with open(file_name, \"r\") as f:\n",
        "    return f.read()\n",
        "\n",
        "working_dir = os.getcwd()  # get our working directory\n",
        "train_file_path = os.path.join(working_dir, 'Yann_LeCunn_bio_devset.txt')\n",
        "test_file_path = os.path.join(working_dir, 'Fei-Fei_Li_bio_testset.txt')\n",
        "\n",
        "text_lecunn = read_file(train_file_path)\n",
        "print(text_lecunn)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGciYNYkBAJg"
      },
      "source": [
        "### Task 1: Examine the biography of Yann Le Cunn, and notice the patterns in which the date expressions occur. List and describe your observations in the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CMr_JYmBAJh"
      },
      "source": [
        "*Your observations go here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap186JxsBAJh"
      },
      "source": [
        "### Task 2: Implement the function *sentence_tokenize_text* so that it splits a text into a list of sentences.\n",
        "\n",
        "*Note: we split the assignment in two parts as the first part used a word-per-line format, while in this second part we look at sentence-per-line.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jomV13DvBAJh"
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "# import the libraries you need\n",
        "### END SOLUTION\n",
        "\n",
        "def sentence_tokenize_text(text):\n",
        "  \"\"\"\n",
        "  :param text: An input text, i.e. a string\n",
        "  :return: A list of strings, where each string is one sentence\n",
        "  \"\"\"\n",
        "  ### BEGIN SOLUTION\n",
        "  # your code goes here\n",
        "  ### END SOLUTION\n",
        "\n",
        "# sentence_tokenize_text(text_geoffrey)  # You can display the result for testing."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w4p7pIcBAJh"
      },
      "source": [
        "###Task 3: Implement the function *extract_date_expressions* so that it extracts date expressions from sentences.\n",
        "**To ensure unbiased annotation of the test data in task 10, only one person of your group will annotate the test data. This person cannot look at the regex that is being developed in this task. The other two can develop the regex together.**\n",
        "\n",
        "The function should take in our list of sentences and return a pandas DataFrame. This DataFrame has two columns:\n",
        "- Date: The extracted date expressions\n",
        "- Sentence: The sentence from which a data expression was extracted\n",
        "\n",
        "**Write your own patterns** and do not rely on libraries that automatically extract date expressions as learning about regular expressions is one of the learning objectives of the exercise.\n",
        "\n",
        "Use the Yann_LeCunn_bio_devset.txt and the manual annotation that you did on the biography of Yoshua Bengio as inspiration for your regular expressions.\n",
        "\n",
        "*Hint: Check out https://regexr.com/ for testing and refining the regular expressions you use to capture date expressions. It also has a handy cheat sheet you can use. *\n",
        "\n",
        "*For coding newbies: You can contact the TAs to get a regex example function in Python.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5N8NDSJPBAJi"
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "# import the libraries you need\n",
        "### END SOLUTION\n",
        "\n",
        "def extract_date_expressions(sentences):\n",
        "  \"\"\"\n",
        "  :param sentences: A list of strings, where each string is one sentence\n",
        "  :return: A pandas DataFrame with the columns\n",
        "                \"Date\" (extracted date expressions as a string)\n",
        "                \"Sentence\" (sentences from which a date expression was extracted)\n",
        "  \"\"\"\n",
        "  ### BEGIN SOLUTION\n",
        "  # your code goes here\n",
        "  ### END SOLUTION\n",
        "\n",
        "# Apply the function to the tokenized text:\n",
        "df_dates_lecunn =  extract_date_expressions(sentence_tokenize_text(text_lecunn))\n",
        "df_dates_lecunn # use this for testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAoFxzQBAJi"
      },
      "source": [
        "### Task 4: Normalization: Implement the function *dates_to_iso8601* so that it converts a date expression string to the ISO 8601 date standard.\n",
        "Then, add the ISO 8601 converted dates as a column (\"ISO\") to our dataframe.\n",
        "\n",
        "You can find more info and examples on https://www.iso.org/iso-8601-date-and-time-format.html.\n",
        "\n",
        "To implement the function check out Python’s inbuilt datetime module. you’ll find functions in there that can make this task a lot easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lJ6vsatpBAJi"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def date_expression_to_iso8601(date_string):\n",
        "  \"\"\"\n",
        "  :param date_string: A string containing a date expression\n",
        "  :return: A string containing the date in ISO 8601 format\n",
        "  \"\"\"\n",
        "  ### BEGIN SOLUTION\n",
        "  # your code goes here\n",
        "  ### END SOLUTION\n",
        "\n",
        "# Now, add a column \"ISO\" to your DataFrame\n",
        "### BEGIN SOLUTION\n",
        "df_dates_lecunn[\"ISO\"] = # YOUR CODE HERE\n",
        "### END SOLUTION\n",
        "df_dates_lecunn  # use this for testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 5: In which respect does the ISO 8601 format defer from the date information present in the text? (If you noticed an additional issue caused by a discrepancy between the standard and the Python implementation please mention this as well.)\n",
        "\n",
        "*Your answere goes here*"
      ],
      "metadata": {
        "id": "msKupXKgFjmH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jr-ekx2BAJj"
      },
      "source": [
        "### Task 6: Combine the previous steps in the function *get_sorted_df_from_file_name* so that it runs the whole date extraction pipeline and returns a DataFrame.\n",
        "**Make sure to order the DataFrame rows chronologically according to the ISO dates!**\n",
        "\n",
        "Consider the following example text:\n",
        "\n",
        "> This is an example text about interesting upcoming dates. Halloween takes place on 31 October 2024. Our Christmas holiday is from Friday 21 December 2024 - Friday 5 January 2025. We will celebrate Sinterklaas on 5 December 2024.\n",
        "\n",
        "Here's an illustration of what the example text's DataFrame should look like:\n",
        "\n",
        "|ISO |Date | Sentence |\n",
        "|----:|----:|:----|\n",
        "|2024-10-31 |31 October 2024| Halloween takes place on 31 October 2024.|\n",
        "|2024-12-05 |5 December 2024| We will celebrate Sinterklaas on 5 December 2024.|\n",
        "|2024-12-21 |21 December 2024| Our Christmas holiday is from Friday 21 December 2024 - Friday 5 January 2025.|\n",
        "|2025-01-05 |5 January 2025| Our Christmas holiday is from Friday 21 December 2024 - Friday 5 January 2025.|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LknbnUtxBAJj"
      },
      "source": [
        "def get_sorted_df_from_file_name(file_name):\n",
        "  \"\"\"\n",
        "  :param file_name: A string containing the full path to a file\n",
        "  :return: A pandas DataFrame with the columns \"Date\", \"Sentence\" and \"ISO\"\n",
        "          (see above), where rows are sorted according to \"ISO\"\n",
        "  \"\"\"\n",
        "  ### BEGIN SOLUTION\n",
        "  # Extract dates, then sort by ISO\n",
        "  ### END SOLUTION\n",
        "\n",
        "get_sorted_df_from_file_name(train_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNno2UGrBAJj"
      },
      "source": [
        "## 2.2 - Manual labeling: Yann_LeCunn_bio_devset.txt\n",
        "To evaluate your date expression pipeline, you first need to have gold labels. For Part 2 we use another labeling format to simplify the regex matching. Let's familiarize ourselves with this format.\n",
        "\n",
        "Look at our example text again:\n",
        "\n",
        "> This is an example text about interesting upcoming dates. Halloween takes place on 31 October 2024. Our Christmas holiday is from Friday 21 December 2024 - Friday 5 January 2025. We will celebrate Sinterklaas on 5 December 2024.\n",
        "\n",
        "\n",
        "This is how we store the gold labels for this example text:\n",
        "~~~python\n",
        "example_manual_labels = [\n",
        "  {\"Dates\": [],\n",
        "    \"Sentence\": \"This is an example text about interesting upcoming dates.\"},\n",
        "  {\"Dates\": [\"2025-10-31\"],\n",
        "    \"Sentence\": \"The next Halloween takes place on 31 October 2024.\"},\n",
        "  {\"Dates\": [\"2024-12-21\", \"2025-01-05\"],\n",
        "    \"Sentence\": \"Our Christmas holiday is from Friday 21 December 2024-Friday 5 January 2025.\"},\n",
        "  {\"Dates\": [\"2024-12-05\"],\n",
        "    \"Sentence\": \"We will celebrate Sinterklaas on 5 December 2024.\"}\n",
        "  ]\n",
        "~~~\n",
        "\n",
        "As you can see, we use a list of dictionaries. We have one dictionary for each sentence. This dictionary has two keys:\n",
        "- Key \"Sentence\": The corresponding value is the sentence (i.e. a string).\n",
        "- Key \"Dates\": The corresponding value is a list of all date expressions (strings; correctly converted to the ISO 8601 date standard) that appear in that sentence. If a sentence does not contain any date expressions, this list is empty.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BphCKIsc4TBS"
      },
      "source": [
        "We've created a helper function that automatically provides a template list based on *your sentence_tokenize_text* function. Run the cell below to get this template for *text_lecunn*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9obC2LWc4NRG"
      },
      "source": [
        "def get_manual_labeling_list(text):\n",
        "  \"\"\"\n",
        "  A helper function to print a manual labeling list in which you only have to\n",
        "  fill in the dates for each sentence.\n",
        "  :param text: An input text, i.e. a string\n",
        "  \"\"\"\n",
        "  tokenized_text = sentence_tokenize_text(text)\n",
        "  return [{\"Dates\": [], \"Sentence\": tokenized_text[i]} for i in range(len(tokenized_text))]\n",
        "\n",
        "get_manual_labeling_list(text_lecunn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L3mGXA94l9C"
      },
      "source": [
        "### Task 7: Manually label all sentences from Yann_LeCunn_bio_devset.txt.   \n",
        "Copy the template list output by our helper function for Yann_LeCunn_bio_devset.txt into the cell below. Then manually fill the list *lecunn_manual_labels* with the dates (in correct ISO 8601 format) from each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qjSQaAyoBAJj"
      },
      "source": [
        "lecunn_manual_labels = [\n",
        "  # Add one dictionary for each sentence here.\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSS73IigBAJk"
      },
      "source": [
        "Now that we have labels for Yann_LeCunn_bio_devset.txt, we can plot a confusion matrix to get an impression of your extraction procedure's performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFu-hHSm1Eor"
      },
      "source": [
        "from utils import plot_confusion_matrix\n",
        "\n",
        "plot_confusion_matrix(manual_labels = lecunn_manual_labels,\n",
        "                      sorted_date_df = get_sorted_df_from_file_name(train_file_path),\n",
        "                      normalize    = False,\n",
        "                      title_names = ['Positive','Negative'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BccP6ZMlBAJk"
      },
      "source": [
        "### Task 8: Manually calculate the precision and recall of your date expression procedure on Yann_LeCunn_bio_devset.txt.\n",
        "Write your calculation into the cell below. Write your *full* calculation including the formula you are using.\n",
        "\n",
        "Hint: You can use $\\LaTeX$ here.\n",
        "- To display a formula inline, surround it by the '\\$' sign.\n",
        "    - For example, '\\$ 4=2^2 \\$' will be displayed like this: $4=2^2$\n",
        "- To display a formula in a block, surround it by '\\$\\$'.\n",
        "    - For example, '\\$\\$ 16=4^2 \\$\\$' will be displayed like this: $$16=4^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qKbw4XwBAJk"
      },
      "source": [
        "*Insert your calculation here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCYrbW-xBAJk"
      },
      "source": [
        "**Now, repeat the following steps until you are satisfied with the performance:**\n",
        "1. Run the date expression procedure on Yann_LeCunn_bio_devset.txt.\n",
        "2. Make adaptations to your code if necessary.\n",
        "3. Go through the output manually and calculate precision and recall. **Make sure the cell above contains the latest calculation.**\n",
        "\n",
        "Once you are satisfied with your performance, proceed to the next part of this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 9: Discuss the difficulties you encountered during each repeat of the above steps to develop the time patterns.  ####"
      ],
      "metadata": {
        "id": "EOg3z_DR-7m2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Describe the difficulties*"
      ],
      "metadata": {
        "id": "FzuItyK2Idzw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMs1nDlJBAJk"
      },
      "source": [
        "## 2.3 - Applying the extraction procedure to the unseen Fei-Fei_Li_bio_testset.txt\n",
        "Next, we will test your date extraction procedure and see how it performs on the unseen file Fei-Fei_Li_bio_testset.txt. First, let's have a look at the text inside this file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sadqgWXRBAJk"
      },
      "source": [
        "text_feifei = read_file(test_file_path)\n",
        "print(text_feifei)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nQw4xmBAJl"
      },
      "source": [
        "### Task 10: Manually label all sentences from Fei-Fei_Li_bio_testset.txt\n",
        "**The one person that didn't work on the regex has to be the person to annotate the test file**\n",
        "\n",
        "The following cell gives you the template list.\n",
        "Fill the list *feifei_manual_labels* (just like you previously did for Yann_LeCunn_bio_devset.txt) in the cell under the following one with the dates from the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be0nekKH5jdo"
      },
      "source": [
        "get_manual_labeling_list(text_feifei)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hPHu0xu2BAJn"
      },
      "source": [
        "feifei_manual_labels = [\n",
        "  # Add one dictionary for each sentence here.\n",
        "\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LOC_Y0e5AOn"
      },
      "source": [
        "**Now, let's run your date expression procedure on the unseen text *Fei-Fei_Li_bio_testset.txt* and look at the resulting DataFrame.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Q37zlx5jdQ"
      },
      "source": [
        "get_sorted_df_from_file_name(test_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ByoHYvMBAJn"
      },
      "source": [
        "### Task 11:  Make adaptations to your date extraction code if necessary. Do not change the functions from the previous part in this assignment, but make your adjustments by changing the three functions below.\n",
        "\n",
        "Currently, each of these \"adapted\" functions just uses the functions from the previous parts. If you want to make any changes to one of the functions, overwrite this return statement with your changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjDEzbp2BAJo"
      },
      "source": [
        "def sentence_tokenize_text_adapted(text):\n",
        "  \"\"\"\n",
        "  :param text: An input text, i.e. a string\n",
        "  :return: A list of strings, where each string is one sentence\n",
        "  \"\"\"\n",
        "  # change this if you want to adapt your original function\n",
        "  return sentence_tokenize_text(text)\n",
        "\n",
        "\n",
        "def extract_date_expressions_adapted(sentences):\n",
        "  \"\"\"\n",
        "  :param sentences: A list of strings, where each string is one sentence\n",
        "  :return: A pandas DataFrame with the columns\n",
        "                \"Date\" (extracted date expressions as a string)\n",
        "                \"Sentence\" (sentences from which a date expression was extracted)\n",
        "  \"\"\"\n",
        "  # change this if you want to adapt your original function\n",
        "  return extract_date_expressions(sentences)\n",
        "\n",
        "\n",
        "def date_expression_to_iso8601_adapted(date_string):\n",
        "  \"\"\"\n",
        "  :param date_string: A string containing a date expression\n",
        "  :return: A string containing the date in ISO 8601 format\n",
        "  \"\"\"\n",
        "  # change this if you want to adapt your original function\n",
        "  return date_expression_to_iso8601(date_string)\n",
        "\n",
        "\n",
        "def get_sorted_df_from_file_name_adapted(file_name):\n",
        "  \"\"\"\n",
        "  :param file_name: A string containing the full path to a file\n",
        "  :return: A pandas DataFrame with the columns \"Date\", \"Sentence\" and \"ISO\"\n",
        "          (see above), where rows are sorted according to \"ISO\"\n",
        "  \"\"\"\n",
        "  # change this if you want to adapt your original function\n",
        "  return get_sorted_df_from_file_name(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBlpaFHOBAJo"
      },
      "source": [
        "### Task 12: Discuss the difficulties you encountered extracting the new timeline. Also address the adaptations that you needed to make for processing the unseen biography Fei-Fei_Li_bio_testset.txt.\n",
        "\n",
        "Write your discussion into the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYiKrWtjBAJo"
      },
      "source": [
        "*Your discussion goes here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOJbQGVj5hwV"
      },
      "source": [
        "**Now, we can evaluate your adapted date expression procedure. Let's plot one confusion matrix for each of the text files. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZhQEZpi4-fE"
      },
      "source": [
        "print('Confusion matrix for Yann Le Cunn:')\n",
        "plot_confusion_matrix(manual_labels = lecunn_manual_labels,\n",
        "                      sorted_date_df = get_sorted_df_from_file_name_adapted(train_file_path),\n",
        "                      normalize    = False,\n",
        "                      title_names = ['Positive','Negative'])\n",
        "\n",
        "print('Confusion matrix for Fei-Fei Li:')\n",
        "plot_confusion_matrix(manual_labels = feifei_manual_labels,\n",
        "                      sorted_date_df = get_sorted_df_from_file_name_adapted(test_file_path),\n",
        "                      normalize    = False,\n",
        "                      title_names = ['Positive','Negative'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mis3cKpXBAJo"
      },
      "source": [
        "### Task 13: Calculate the precision and recall of your adapted date expression procedure on both Yann_LeCunn_bio_devset.txt and Fei-Fei_Li_bio_testset.txt.\n",
        "\n",
        "Write your calculations into the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXBmTI_jBAJo"
      },
      "source": [
        "*Your precision and recall calculations go here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuyKThl2BAJp"
      },
      "source": [
        "### Task 14: Compare the precision and recall scores on Yann_LeCunn_bio_devset.txt and Fei-Fei_Li_bio_testset.txt. Address the following points:\n",
        "- Did the values of Yann_LeCunn_bio_devset.txt change after your adaptions?\n",
        "- Are there any differences between the two texts?\n",
        "- If so, where does this difference come from?\n",
        "- What does this difference mean in terms of generalizability?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwZM7OBsBAJp"
      },
      "source": [
        "*Your answer goes here*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 15: Take a closer look at the errors your automatic extraction method makes. What is happening there?"
      ],
      "metadata": {
        "id": "X_yDquKREY5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your answer goes here*"
      ],
      "metadata": {
        "id": "T0-Enf23IVMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 16: Reflect on the relation between date mentions in the texts and the events that they denote, reflect on duration and overlap of events. (max. 4 sentences)"
      ],
      "metadata": {
        "id": "4ISR7Wx7IY2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your answer goes here*"
      ],
      "metadata": {
        "id": "_wXoPYvWIevI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 - Finding matching events"
      ],
      "metadata": {
        "id": "FEYCsyHRHB8_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQEmxaF3BAJp"
      },
      "source": [
        "### Task 17: Find the matching events (i.e. overlapping dates in the two biographical timelines) between the two timelines.\n",
        "\n",
        "You could do this in one of the following ways:\n",
        "- **Command line** We highly encourage you to use the ‘comm’ function on your ISO-8601 dates in your command line (more info and example: https://www.computerhope.com/unix/ucomm.htm. Note that this command also works on Mac OS/Windows).\n",
        "- **Python** It is also allowed to find the matching events programmatically in Python.\n",
        "- **Online tool ** You can use an online tool (e.g. https://text-compare.com/).\n",
        "\n",
        "**Important: Do not search for matching events manually!**\n",
        "\n",
        "Please put the command, the code or the link to the website you used into the cell below or briefly describe how you found the matching events.  \n",
        "\n",
        "Then, also paste the list of matching events (in ISO-8601 format) into that cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seCjCDB5BAJp"
      },
      "source": [
        "*Your description goes here*\n",
        "\n",
        "*Your list goes here*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMoICcPCBAJq"
      },
      "source": [
        "### Task 18: Discussion of matching events\n",
        "1. Discuss the list of matching events that you found.\n",
        "2. When going through the texts manually, do you find matching events that you did not find programmatically/automatically?\n",
        "3. If so, what could be the reason(s) for this? Discuss your answers to these questions and any other difficulties you encountered during the extraction of matching events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9EtialZcvRS"
      },
      "source": [
        "*Your answer goes here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuRKcGAw-5wG"
      },
      "source": [
        "print('Congratulations! You finished this assignment!')\n",
        "print('We would like to thank Theo Kent for letting us use his notebook as a basis for this assignment!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please look at the ***Handing in the assignment*** section for instructions on what to hand in."
      ],
      "metadata": {
        "id": "HKT37cC8x7KZ"
      }
    }
  ]
}